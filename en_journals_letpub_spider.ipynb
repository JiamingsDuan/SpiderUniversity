{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c020b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bc82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201 Bioscience Journal\n",
      "1202 BIOSCIENCE REPORTS\n",
      "1203 BIOSENSORS & BIOELECTRONICS\n",
      "1204 BIOSTATISTICS\n",
      "1205 BIOSYSTEMS\n",
      "1206 BIOSYSTEMS ENGINEERING\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm.notebook import trange\n",
    "from lxml.etree import HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_toolbelt import SSLAdapter\n",
    "\n",
    "adapter = SSLAdapter('TLSv1')\n",
    "s = requests.Session()\n",
    "s.mount('https://', adapter)\n",
    "\n",
    "save_path = './letpub_journals/json/'\n",
    "\n",
    "proxy = '103.215.34.6:8080'\n",
    "\n",
    "proxies = {\n",
    "    'http': 'http://' + proxy,\n",
    "}\n",
    "\n",
    "\n",
    "def judge(judge_list):\n",
    "    if len(judge_list) != 0:\n",
    "        judge_item = ' '.join(judge_list)\n",
    "        return judge_item.replace('\\n', '')\n",
    "    else:\n",
    "        judge_item = ''\n",
    "        return judge_item\n",
    "\n",
    "\n",
    "def fetch_text(element, item):\n",
    "    journal_information_set = HTML(str(element)).xpath(item)\n",
    "    journal_information = judge(journal_information_set)\n",
    "    return journal_information\n",
    "\n",
    "\n",
    "def make_dir(rs):\n",
    "    if not os.path.exists(rs):\n",
    "        os.makedirs(rs)\n",
    "\n",
    "\n",
    "make_dir(save_path)\n",
    "        \n",
    "# 【1】请求\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,'\n",
    "              'application/signed-exchange;v=b3;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cookie': '_ga=GA1.3.909610943.1639118789; PHPSESSID=sk0r83jr39vgspirame2rnip72; '\n",
    "              'Hm_lvt_a94e857ae4207c3ac8fcfd63f6604f22=1642656196; _gid=GA1.3.1203548548.1642656197; _gat=1; '\n",
    "              '__utma=189275190.909610943.1639118789.1642400610.1642656197.32; __utmc=189275190; '\n",
    "              '__utmz=189275190.1642656197.32.4.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmt=1; '\n",
    "              '__utmb=189275190.10.10.1642656197; Hm_lpvt_a94e857ae4207c3ac8fcfd63f6604f22=1642656212',\n",
    "    'Host': 'www.letpub.com.cn',\n",
    "    'Referer': 'https://www.letpub.com.cn/index.php?page=journalapp',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/96.0.4664.110 Safari/537.36 Edg/96.0.1054.62',\n",
    "}\n",
    "for ids in range(1201, 1301):\n",
    "    url = 'https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=' + str(ids)\n",
    "    response = requests.get(url=url, headers=headers, proxies=proxies)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table_set = soup.find_all('table', attrs={'class': 'table_yjfx'})\n",
    "    if len(table_set) == 0:\n",
    "        print(ids, 'wait')\n",
    "    tr_soup = BeautifulSoup(str(table_set[1]), 'html.parser')\n",
    "\n",
    "    # 【2】解析\n",
    "    # title\n",
    "    pattern_1 = tr_soup.find(text=re.compile(r'期刊名字')).__dict__\n",
    "    journal_title = fetch_text(pattern_1['next_element'], '*//a/text()')\n",
    "    print(ids, journal_title)\n",
    "    # ISSN\n",
    "    pattern_2 = tr_soup.find(text=re.compile(r'期刊ISSN')).__dict__\n",
    "    journal_ISSN = fetch_text(pattern_2['next_element'], '*//text()')\n",
    "\n",
    "    # influence_index\n",
    "    pattern_3 = tr_soup.find(text=re.compile(r'2020-2021最新IF')).parent.next_sibling.__dict__\n",
    "    journal_IF = fetch_text(pattern_3['next_element'], '*//text()').replace(' ', '')\n",
    "\n",
    "    # self_citation\n",
    "    pattern_4 = tr_soup.find(text=re.compile(r'2020-2021自引率')).__dict__\n",
    "    journal_SC = fetch_text(pattern_4['next_element'], '*//text()').replace('点击查看自引率趋势图', '').split('%')[0] + '%'\n",
    "\n",
    "    # H_index\n",
    "    pattern_5 = tr_soup.find(text=re.compile(r'h-index')).parent.next_sibling.__dict__\n",
    "    journal_HI = fetch_text(pattern_5['next_element'], '*//text()')\n",
    "\n",
    "    # cite_score & SJR & ........\n",
    "    pattern_6 = tr_soup.find(text=re.compile(r'CiteScore')).next_sibling.__dict__\n",
    "    if fetch_text(pattern_6['next_element'], '*//text()') != '暂无CiteScore数据':\n",
    "        cite_score_soup = BeautifulSoup(str(pattern_6['next_element']), 'html.parser')\n",
    "        pattern_6_son = cite_score_soup.find(text=re.compile(r'CiteScore'))\n",
    "        pattern_6_son = pattern_6_son.parent.parent.next_sibling.__dict__\n",
    "        journal_cite_score = fetch_text(pattern_6_son['contents'][0], '*//text()')\n",
    "        journal_SJR = fetch_text(pattern_6_son['contents'][1], '*//text()')\n",
    "        journal_SNIP = fetch_text(pattern_6_son['contents'][2], '*//text()')\n",
    "        cite_score_list_soup = BeautifulSoup(str(pattern_6_son['contents'][-1]), 'html.parser')\n",
    "        pattern_6_grandson = cite_score_list_soup.find_all('tr', attrs={'': ''})\n",
    "\n",
    "        cite_score_lists = []\n",
    "        for cite_score_row_index in range(1, len(pattern_6_grandson)):\n",
    "            cite_score_dict = {'journal_subject': fetch_text(pattern_6_grandson[cite_score_row_index], '*//td[1]/text()'),\n",
    "                               'journal_quarter': fetch_text(pattern_6_grandson[cite_score_row_index], '*//td[2]/text()'),\n",
    "                               'journal_queue': fetch_text(pattern_6_grandson[cite_score_row_index], '*//td[3]/text()'),\n",
    "                               'journal_rate': fetch_text(pattern_6_grandson[cite_score_row_index],\n",
    "                                                          '*//td[4]/div/div/@lay-percent')}\n",
    "            cite_score_lists.append(cite_score_dict)\n",
    "    else:\n",
    "        journal_cite_score = ''\n",
    "        journal_SJR = ''\n",
    "        journal_SNIP = ''\n",
    "        cite_score_lists = []\n",
    "\n",
    "    # abstract\n",
    "    pattern_7 = tr_soup.find(text=re.compile(r'期刊简介')).parent.next_sibling.__dict__\n",
    "    if len(pattern_7['contents']) != 0:\n",
    "        journal_abstract = fetch_text(pattern_7['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_abstract = ''\n",
    "\n",
    "    # authority_url\n",
    "    pattern_8 = tr_soup.find(text=re.compile(r'期刊官方网站')).parent.next_sibling.__dict__\n",
    "    journal_authority_url = fetch_text(pattern_8['next_element'], '*//a/@href')\n",
    "\n",
    "    # send_url\n",
    "    pattern_9 = tr_soup.find(text=re.compile(r'期刊投稿网址')).parent.next_sibling.__dict__\n",
    "    journal_send_url = fetch_text(pattern_9['next_element'], '*//a/@href')\n",
    "\n",
    "    # author_direction_url\n",
    "    # pattern_10 = tr_soup.find(text=re.compile(r'作者指南网址')).parent.next_sibling.__dict__\n",
    "    # if len(pattern_10['contents']) != 0:\n",
    "    #     journal_author_direction_url = fetch_text(pattern_10['next_element'], '*//a/@href')\n",
    "    # else:\n",
    "    #     journal_author_direction_url = ''\n",
    "\n",
    "    # database_open\n",
    "    pattern_11 = tr_soup.find(text=re.compile(r'是否OA开放访问')).parent.next_sibling.__dict__\n",
    "    if len(pattern_11['contents']) != 0:\n",
    "        journal_database_open = fetch_text(pattern_11['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_database_open = ''\n",
    "\n",
    "    # communication_form\n",
    "    pattern_12 = tr_soup.find(text=re.compile(r'通讯方式')).parent.next_sibling.__dict__\n",
    "    if len(pattern_12['contents']) != 0:\n",
    "        journal_communication_form = fetch_text(pattern_12['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_communication_form = ''\n",
    "\n",
    "    # publisher\n",
    "    pattern_13 = tr_soup.find(text=re.compile(r'通讯方式')).parent.next_sibling.__dict__\n",
    "    if len(pattern_13['contents']) != 0:\n",
    "        journal_publisher = fetch_text(pattern_13['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_publisher = ''\n",
    "\n",
    "    # Research directions involved\n",
    "    pattern_14 = tr_soup.find(text=re.compile(r'涉及的研究方向')).parent.next_sibling.__dict__\n",
    "    if len(pattern_14['contents']) != 0:\n",
    "        journal_involved_research_direction = fetch_text(pattern_14['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_involved_research_direction = ''\n",
    "\n",
    "    # published region or country\n",
    "    pattern_15 = tr_soup.find(text=re.compile(r'出版国家或地区')).parent.next_sibling.__dict__\n",
    "    if len(pattern_15['contents']) != 0:\n",
    "        journal_published_region = fetch_text(pattern_15['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_published_region = ''\n",
    "\n",
    "    # published language\n",
    "    pattern_16 = tr_soup.find(text=re.compile(r'出版语言')).parent.next_sibling.__dict__\n",
    "    if len(pattern_16['contents']) != 0:\n",
    "        journal_language = fetch_text(pattern_16['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_language = ''\n",
    "\n",
    "    # published period\n",
    "    pattern_17 = tr_soup.find(text=re.compile(r'出版周期')).parent.next_sibling.__dict__\n",
    "    if len(pattern_17['contents']) != 0:\n",
    "        journal_period = fetch_text(pattern_17['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_period = ''\n",
    "\n",
    "    # created year\n",
    "    pattern_18 = tr_soup.find(text=re.compile(r'出版年份')).parent.next_sibling.__dict__\n",
    "    if len(pattern_18['contents']) != 0:\n",
    "        journal_created_year = fetch_text(pattern_18['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_created_year = ''\n",
    "\n",
    "    # articles per year\n",
    "    pattern_27 = tr_soup.find(text=re.compile(r'年文章数')).parent.next_sibling.__dict__\n",
    "    if len(pattern_27['contents']) != 0:\n",
    "        journal_articles = fetch_text(pattern_18['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_articles = ''\n",
    "\n",
    "    # gold OA rate\n",
    "    pattern_19 = tr_soup.find(text=re.compile(r'Gold OA文章占比')).parent.next_sibling.__dict__\n",
    "    if len(pattern_19['contents']) != 0:\n",
    "        journal_OA_rate = fetch_text(pattern_19['next_element'], '*//text()').split('%')[0] + '%'\n",
    "    else:\n",
    "        journal_OA_rate = ''\n",
    "\n",
    "    # research articles rates\n",
    "    pattern_20 = tr_soup.find(text=re.compile(r'研究类文章占比')).parent.next_sibling.__dict__\n",
    "    if len(pattern_27['contents']) != 0:\n",
    "        journal_research_articles = fetch_text(pattern_20['next_element'], '*//text()')\n",
    "    else:\n",
    "        journal_research_articles = ''\n",
    "\n",
    "    # SCI quarter\n",
    "    pattern_21 = tr_soup.find(text=re.compile(r'期刊SCI分区')).parent.next_sibling.__dict__\n",
    "    journal_sci_quarter_soup = BeautifulSoup(str(pattern_21['next_element']), 'html.parser')\n",
    "    journal_sci_quarter_set = journal_sci_quarter_soup.find_all('tr', attrs={'': ''})\n",
    "\n",
    "    journal_sci_quarter_list = []\n",
    "    for journal_sci_quarter_index in range(1, len(journal_sci_quarter_set)):\n",
    "        journal_sci_quarter_dict = {\n",
    "            'journal_sci_subject': fetch_text(journal_sci_quarter_set[journal_sci_quarter_index], '*//td/text()'),\n",
    "            'journal_sci_quarter': fetch_text(journal_sci_quarter_set[journal_sci_quarter_index], '*//td/span['\n",
    "                                                                                                  '@style=\"background: '\n",
    "                                                                                                  '#FFEEEE; border: 1px '\n",
    "                                                                                                  'solid #FFAAAA; '\n",
    "                                                                                                  'color:#3b5998; '\n",
    "                                                                                                  'float:right; '\n",
    "                                                                                                  'padding:4px;\"]/text()'),\n",
    "        }\n",
    "        journal_sci_quarter_list.append(journal_sci_quarter_dict)\n",
    "\n",
    "    # Coverage of SCI Journals\n",
    "    pattern_22 = tr_soup.find(text=re.compile(r'SCI期刊收录coverage')).parent.next_sibling.__dict__\n",
    "    journal_sci_coverage_soup = BeautifulSoup(str(pattern_22['parent']), 'html.parser')\n",
    "    journal_sci_coverage_set = journal_sci_coverage_soup.find_all('a', attrs={'target': '_blank'})\n",
    "    journal_sci_coverage_list = []\n",
    "    for journal_sci_coverage_index in range(len(journal_sci_coverage_set)):\n",
    "        journal_sci_coverage = fetch_text(journal_sci_coverage_set[journal_sci_coverage_index], '*//text()')\n",
    "        journal_sci_coverage_list.append(journal_sci_coverage)\n",
    "\n",
    "    # Chinese Academy of Sciences Early warning list\n",
    "    pattern_23 = tr_soup.find(text=re.compile(r'国际期刊预警')).parent.next_sibling.__dict__\n",
    "    journal_cas_warning_soup = BeautifulSoup(str(pattern_23['parent']), 'html.parser')\n",
    "    journal_cas_warning = fetch_text(pattern_23['next_element'], '*//text()')\n",
    "    # journal_cas_warning_previous = fetch_text(pattern_23['next_element'], '*//br/text()')\n",
    "\n",
    "    # Average employment ratio\n",
    "    # pattern_24 = tr_soup.find(text=re.compile(r'平均录用比例')).parent.next_sibling.__dict__\n",
    "    # journal_average_employment_ratio = fetch_text(pattern_24['next_element'], '*//text()')\n",
    "\n",
    "    # Division of SCI journals of Chinese Academy of Sciences (latest basic edition in December 2021)\n",
    "    pattern_25 = tr_soup.find(text=re.compile(r'2021年12月最新基础版')).parent.parent.next_sibling.__dict__\n",
    "    cas_2021_basic_subject_large = fetch_text(pattern_25['contents'][2], '//table[@width=\"100%\"]/tr[2]/td[1]/text()')\n",
    "    cas_2021_basic_subject_quarter = fetch_text(pattern_25['contents'][2], '//table[@width=\"100%\"]/tr[2]/td['\n",
    "                                                                           '1]/span[ '\n",
    "                                                                           '@style=\"background: #FFEEEE; '\n",
    "                                                                           'border: 1px solid #FFAAAA; '\n",
    "                                                                           'color:#3b5998; '\n",
    "                                                                           'float:right; padding:4px;\"]/text()')\n",
    "\n",
    "    cas_2021_basic_subject_short_soup = BeautifulSoup(str(pattern_25['contents'][2]), 'html.parser')\n",
    "    cas_2021_basic_subject_short_table = cas_2021_basic_subject_short_soup.find_all('table', attrs={'width': '99%'})\n",
    "    if len(cas_2021_basic_subject_short_table) != 0:\n",
    "        cas_2021_basic_subject_short_soup_son = BeautifulSoup(str(cas_2021_basic_subject_short_table[0]), 'html.parser')\n",
    "        cas_2021_basic_subject_short_set = cas_2021_basic_subject_short_soup_son.find_all('tr')\n",
    "        cas_2021_basic_subject_short_list = []\n",
    "        for cas_2021_basic_subject_short_index in range(len(cas_2021_basic_subject_short_set)):\n",
    "            subject_short_item = '//tr/td[1]/text()'\n",
    "            subject_short_quarter_item = '//tr/td[2]/span[@style=\"background: #FFEEEE; border: 1px solid #FFAAAA; ' \\\n",
    "                                         'color:#3b5998; float:right; padding:4px;\"]/text() '\n",
    "            cas_2021_basic_subject_short_dict = {\n",
    "                'subject_short': fetch_text(str(cas_2021_basic_subject_short_set[cas_2021_basic_subject_short_index]),\n",
    "                                            subject_short_item),\n",
    "                'subject_short_quarter': fetch_text(\n",
    "                    str(cas_2021_basic_subject_short_set[cas_2021_basic_subject_short_index]),\n",
    "                    subject_short_quarter_item)\n",
    "            }\n",
    "            cas_2021_basic_subject_short_list.append(cas_2021_basic_subject_short_dict)\n",
    "    else:\n",
    "        cas_2021_basic_subject_short_list = []\n",
    "    cas_2021_basic_subject_top = fetch_text(pattern_25['contents'][2], '//table[@width=\"100%\"]/tr[2]/td[3]/text()')\n",
    "    cas_2021_basic_subject_survey = fetch_text(pattern_25['contents'][2], '//table[@width=\"100%\"]/tr[2]/td[4]/text()')\n",
    "\n",
    "    # Division of SCI journals of Chinese Academy of Sciences (latest upgrade edition in December 2021)\n",
    "    pattern_26 = tr_soup.find(text=re.compile(r'2021年12月最新升级版')).parent.parent.next_sibling.__dict__\n",
    "    cas_2021_upgrade_subject_large = fetch_text(pattern_26['contents'][0], '//table[@width=\"100%\"]/tr[2]/td[1]/text()')\n",
    "    cas_2021_upgrade_subject_quarter = fetch_text(pattern_26['contents'][0], '//table[@width=\"100%\"]/tr[2]/td['\n",
    "                                                                             '1]/span[ '\n",
    "                                                                             '@style=\"background: #FFEEEE; '\n",
    "                                                                             'border: 1px solid #FFAAAA; '\n",
    "                                                                             'color:#3b5998; '\n",
    "                                                                             'float:right; padding:4px;\"]/text()')\n",
    "\n",
    "    cas_2021_upgrade_subject_short_soup = BeautifulSoup(str(pattern_26['contents'][0]), 'html.parser')\n",
    "    cas_2021_upgrade_subject_short_table = cas_2021_upgrade_subject_short_soup.find_all('table', attrs={'width': '99%'})\n",
    "    if len(cas_2021_upgrade_subject_short_table) != 0:\n",
    "        cas_2021_upgrade_subject_short_soup_son = BeautifulSoup(str(cas_2021_upgrade_subject_short_table[0]), 'html.parser')\n",
    "        cas_2021_upgrade_subject_short_set = cas_2021_upgrade_subject_short_soup_son.find_all('tr')\n",
    "        cas_2021_upgrade_subject_short_list = []\n",
    "        for cas_2021_upgrade_subject_short_index in range(len(cas_2021_upgrade_subject_short_set)):\n",
    "            subject_short_item = '//tr/td[1]/text()'\n",
    "            subject_short_quarter_item = '//tr/td[2]/span[@style=\"background: #FFEEEE; border: 1px solid #FFAAAA; ' \\\n",
    "                                         'color:#3b5998; float:right; padding:4px;\"]/text() '\n",
    "            cas_2021_upgrade_subject_short_dict = {\n",
    "                'subject_short': fetch_text(str(cas_2021_upgrade_subject_short_set[cas_2021_upgrade_subject_short_index]),\n",
    "                                            subject_short_item),\n",
    "                'subject_short_quarter': fetch_text(\n",
    "                    str(cas_2021_upgrade_subject_short_set[cas_2021_upgrade_subject_short_index]),\n",
    "                    subject_short_quarter_item)\n",
    "            }\n",
    "            cas_2021_upgrade_subject_short_list.append(cas_2021_upgrade_subject_short_dict)\n",
    "    else:\n",
    "        cas_2021_upgrade_subject_short_list = []\n",
    "    cas_2021_upgrade_subject_top = fetch_text(pattern_26['contents'][0], '//table[@width=\"100%\"]/tr[2]/td[3]/text()')\n",
    "    cas_2021_upgrade_subject_survey = fetch_text(pattern_26['contents'][0], '//table[@width=\"100%\"]/tr[2]/td[4]/text()')\n",
    "\n",
    "    # against the crawler\n",
    "    bit = random.randint(7, 10)\n",
    "    digit = random.randint(7, 10)\n",
    "    waiting = bit * 10 + digit\n",
    "    sleep(waiting)\n",
    "#     for sec in trange(waiting):\n",
    "#         sleep(0.1)\n",
    "\n",
    "    let_pub = {\n",
    "        'title': journal_title,\n",
    "        'ISSN': journal_ISSN,\n",
    "        'IF': journal_IF,\n",
    "        'self_citation': journal_SC,\n",
    "        'H_index': journal_HI,\n",
    "        'CiteScore': journal_cite_score,\n",
    "        'SJR': journal_SJR,\n",
    "        'SNIP': journal_SNIP,\n",
    "        'CiteScoreRanking': cite_score_lists,\n",
    "        'introduction': journal_abstract,\n",
    "        'authority_url': journal_authority_url,\n",
    "        'contribute_url': journal_send_url,\n",
    "        'OA': journal_database_open,\n",
    "        'communication_form': journal_communication_form,\n",
    "        'publisher': journal_publisher,\n",
    "        'research_direction': journal_involved_research_direction,\n",
    "        'region': journal_published_region,\n",
    "        'language': journal_language,\n",
    "        'period': journal_period,\n",
    "        'created_year': journal_created_year,\n",
    "        'articles': journal_articles,\n",
    "        'OA_rate': journal_OA_rate,\n",
    "        'type_research': journal_research_articles,\n",
    "        'sci_coverage': journal_sci_coverage_list,\n",
    "        'sci_quarter': journal_sci_quarter_list,\n",
    "        'cas_basic_large': cas_2021_basic_subject_large,\n",
    "        'cas_basic_quarter': cas_2021_basic_subject_quarter,\n",
    "        'cas_basic_short': cas_2021_basic_subject_short_list,\n",
    "        'cas_basic_top': cas_2021_basic_subject_top,\n",
    "        'cas_basic_survey': cas_2021_basic_subject_survey,\n",
    "        'cas_upgrade_large': cas_2021_upgrade_subject_large,\n",
    "        'cas_upgrade_quarter': cas_2021_upgrade_subject_quarter,\n",
    "        'cas_upgrade_short': cas_2021_upgrade_subject_short_list,\n",
    "        'cas_upgrade_top': cas_2021_upgrade_subject_top,\n",
    "        'cas_upgrade_survey': cas_2021_upgrade_subject_survey,\n",
    "    }\n",
    "\n",
    "    # 【3】存储\n",
    "    journal_info_json = json.dumps(let_pub, ensure_ascii=False, indent=4)\n",
    "    with open(save_path + str(ids) + '.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(journal_info_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04b240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
